{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Train Various Regression Models and Compare Their Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will train and evaluate regression models. Note that just as classification models are called 'classifiers,' regression models are called 'regressors.'\n",
    "\n",
    "In this assignment, you will:\n",
    "\n",
    "1. Load the \"cell2celltrain\" data set.\n",
    "2. Train and evaluate a linear regression model. \n",
    "2. Perform a grid search to identify and fit a cross-validated optimal decision tree regressor. \n",
    "3. Fit the optimal decision tree regressor to the training data and make predictions on the test data.\n",
    "4. Train and evaluate an optimized gradient boosted decision tree and an optimized random forest.\n",
    "5. Visualize all of the models' performances.\n",
    "\n",
    "**<font color='red'>Note: Some of the code cells in this notebook may take a while to run.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the \"cell2celltrain\" data set. This data set is already preprocessed, with the proper formatting, outliers and missing values taken care of, and all numerical columns scaled to the [0, 1] interval. One-hot encoding has been performed. Run the cell below to load the data set and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not remove or edit the line below:\n",
    "filename = os.path.join(os.getcwd(), \"data\", \"cell2celltrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Load the data and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>ChildrenInHH</th>\n",
       "      <th>HandsetRefurbished</th>\n",
       "      <th>HandsetWebCapable</th>\n",
       "      <th>TruckOwner</th>\n",
       "      <th>RVOwner</th>\n",
       "      <th>HomeownershipKnown</th>\n",
       "      <th>BuysViaMailOrder</th>\n",
       "      <th>RespondsToMailOffers</th>\n",
       "      <th>...</th>\n",
       "      <th>Occupation_Crafts</th>\n",
       "      <th>Occupation_Homemaker</th>\n",
       "      <th>Occupation_Other</th>\n",
       "      <th>Occupation_Professional</th>\n",
       "      <th>Occupation_Retired</th>\n",
       "      <th>Occupation_Self</th>\n",
       "      <th>Occupation_Student</th>\n",
       "      <th>Married_False</th>\n",
       "      <th>Married_True</th>\n",
       "      <th>Married_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000002</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000010</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000014</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000026</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Churn  ChildrenInHH  HandsetRefurbished  HandsetWebCapable  \\\n",
       "0     3000002   True         False               False               True   \n",
       "1     3000010   True          True               False              False   \n",
       "2     3000014  False          True               False              False   \n",
       "3     3000022  False         False               False               True   \n",
       "4     3000026   True         False               False              False   \n",
       "\n",
       "   TruckOwner  RVOwner  HomeownershipKnown  BuysViaMailOrder  \\\n",
       "0       False    False                True              True   \n",
       "1       False    False                True              True   \n",
       "2       False    False               False             False   \n",
       "3       False    False                True              True   \n",
       "4       False    False                True              True   \n",
       "\n",
       "   RespondsToMailOffers  ...  Occupation_Crafts  Occupation_Homemaker  \\\n",
       "0                  True  ...                0.0                   0.0   \n",
       "1                  True  ...                0.0                   0.0   \n",
       "2                 False  ...                1.0                   0.0   \n",
       "3                  True  ...                0.0                   0.0   \n",
       "4                  True  ...                0.0                   0.0   \n",
       "\n",
       "   Occupation_Other  Occupation_Professional  Occupation_Retired  \\\n",
       "0               0.0                      1.0                 0.0   \n",
       "1               0.0                      1.0                 0.0   \n",
       "2               0.0                      0.0                 0.0   \n",
       "3               1.0                      0.0                 0.0   \n",
       "4               0.0                      1.0                 0.0   \n",
       "\n",
       "   Occupation_Self  Occupation_Student  Married_False  Married_True  \\\n",
       "0              0.0                 0.0            1.0           0.0   \n",
       "1              0.0                 0.0            0.0           1.0   \n",
       "2              0.0                 0.0            0.0           1.0   \n",
       "3              0.0                 0.0            1.0           0.0   \n",
       "4              0.0                 0.0            0.0           1.0   \n",
       "\n",
       "   Married_nan  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we mostly focused on classification problems, using the binary 'Churn' column as the class label for prediction. For this exercise, you will focus on a regression problem and predict a continuous outcome.\n",
    "\n",
    "Your model will predict an individual's income; the label is going to be 'IncomeGroup'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labeled Examples \n",
    "\n",
    "<b>Task</b>: Create labeled examples from DataFrame `df`. \n",
    "In the code cell below carry out the following steps:\n",
    "\n",
    "* Get the `IncomeGroup` column from DataFrame `df` and assign it to the variable `y`. This will be our label.\n",
    "* Get all other columns from DataFrame `df` and assign them to the variable `X`. These will be our features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "y = df['IncomeGroup'] \n",
    "X = df.drop(columns = 'Churn', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Labeled Examples Into Training and Test Sets\n",
    "\n",
    "<b>Task</b>: In the code cell below create training and test sets out of the labeled examples. \n",
    "\n",
    "1. Use scikit-learn's `train_test_split()` function to create the data sets.\n",
    "\n",
    "2. Specify:\n",
    "    * A test set that is 30 percent (.30) of the size of the data set.\n",
    "    * A seed value of '1234'. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fit and Evaluate Two Regression Models: Linear Regression and Decision Tree\n",
    "\n",
    "### a. Fit and Evaluate a Linear Regression\n",
    "\n",
    "You will use the scikit-learn `LinearRegression` class to create a linear regression model. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "First let's import `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Initialize a scikit-learn `LinearRegression` model object with no arguments, and fit the model to the training data. The model object should be named `lr_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create the model object below and assign to variable 'lr_model'\n",
    "# YOUR CODE HERE\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "# YOUR CODE HERE\n",
    "lr_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Test your model on the test set (`X_test`). Call the ``predict()`` method  to use the fitted model to generate a vector of predictions on the test set. Save the result to the variable ``y_lr_pred``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_lr_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our linear regression model, we will compute the RMSE (root mean square error) on the test set. RMSE is a metric used to evaluate regression models. RMSE finds the differences between the predicted values and the actual values. \n",
    "\n",
    "To compute the RMSE, we will use the scikit-learn ```mean_squared_error()``` function, which computes the MSE between ```y_test``` and ```y_lr_pred```. We will specify the parameter `squared=False` to obtain the RMSE. \n",
    "\n",
    "We will also use the coefficient of determination, also known as $R^2$. $R^2$ is a measure of the proportion of variability in the prediction that the model was able to make using the input data. An $R^2$ value of 1 is perfect and 0 implies no explanatory value. We can use scikit-learn's ```r2_score()``` function to compute it. \n",
    "\n",
    "\n",
    "<b>Task</b>: In the code cell below, do the following:\n",
    "\n",
    "1. Call the `mean_squared_error()` function with arguments `y_test` and `y_lr_pred` and the parameter `squared=False` to find the RMSE. Save your result to the variable `lr_rmse`.\n",
    "\n",
    "2. Call the `r2_score()` function with the arguments `y_test` and `y_lr_pred`.  Save the result to the variable `lr_r2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 3.18136519811691e-11\n",
      "[LR] R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "lr_rmse = mean_squared_error(y_test, y_lr_pred, squared=False)\n",
    "lr_r2 = r2_score(y_test, y_lr_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(lr_rmse))\n",
    "print('[LR] R2: {0}'.format(lr_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Fit and Evaluate a Decision Tree Using GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the scikit-learn `DecisionTreeRegressor` class to create a decision tree regressor. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html).\n",
    "\n",
    "First let's import `DecisionTreeRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up a Parameter Grid \n",
    "\n",
    "<b>Task</b>: Create a dictionary called `param_grid` that contains possible hyperparameter values for `max_depth` and `min_samples_leaf`. The dictionary should contain the following key/value pairs:\n",
    "\n",
    "* a key called 'max_depth' with a value which is a list consisting of the integers 4 and 8\n",
    "* a key called 'min_samples_leaf' with a value which is a list consisting of the integers 25 and 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "param_grid = {'max_depth': [4,8], 'min_samples_leaf': [25, 50]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use `GridSearchCV` to fit a grid of decision tree regressors and search over the different values of hyperparameters `max_depth` and `min_samples_leaf` to find the ones that results in the best 3-fold cross-validation (CV) score.\n",
    "\n",
    "\n",
    "You will pass the following arguments to `GridSearchCV()`:\n",
    "\n",
    "1. A decision tree **regressor** model object.\n",
    "2. The `param_grid` variable.\n",
    "3. The number of folds (`cv=3`).\n",
    "4. The scoring method `scoring='neg_root_mean_squared_error'`. Note that `neg_root_mean_squared_error` returns the negative RMSE.\n",
    "\n",
    "\n",
    "Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Running Grid Search...')\n",
    "\n",
    "# 1. Create a DecisionTreeRegressor model object without supplying arguments. \n",
    "#    Save the model object to the variable 'dt_regressor'\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor() # YOUR CODE HERE\n",
    "\n",
    "\n",
    "# 2. Run a Grid Search with 3-fold cross-validation and assign the output to the object 'dt_grid'.\n",
    "#    * Pass the model and the parameter grid to GridSearchCV()\n",
    "#    * Set the number of folds to 3\n",
    "#    * Specify the scoring method\n",
    "\n",
    "dt_grid = GridSearchCV(dt_regressor, param_grid, cv=3, scoring='neg_root_mean_squared_error') # YOUR CODE HERE\n",
    "\n",
    "\n",
    "# 3. Fit the model (use the 'grid' variable) on the training data and assign the fitted model to the \n",
    "#    variable 'dt_grid_search'\n",
    "\n",
    "dt_grid_search = dt_grid.fit(X_train, y_train) # YOUR CODE HERE\n",
    "\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below prints the RMSE score of the best model using the `best_score_` attribute of the fitted grid search object `dt_grid_search`. Note that specifying a scoring method of `neg_root_mean_squared_error` will result in the negative RMSE, so we will multiply `dt_grid_search.best_score` by -1 to obtain the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] RMSE for the best model is : 0.00\n"
     ]
    }
   ],
   "source": [
    "rmse_DT = -1 * dt_grid_search.best_score_\n",
    "print(\"[DT] RMSE for the best model is : {:.2f}\".format(rmse_DT) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, obtain the best model hyperparameters identified by the grid search and save them to the variable `dt_best_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 25]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "dt_best_params = []\n",
    "dt_best_params.append(dt_grid_search.best_estimator_.max_depth)\n",
    "dt_best_params.append(dt_grid_search.best_estimator_.min_samples_leaf)\n",
    "\n",
    "dt_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, initialize a `DecisionTreeRegressor` model object, supplying the best values of hyperparameters `max_depth` and `min_samples_leaf` as arguments.  Name the model object `dt_model`. Then fit the model `dt_model` to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=4,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=25, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create the  model object below and assign to variable 'dt_model'\n",
    "# YOUR CODE HERE\n",
    "dt_model = DecisionTreeRegressor(max_depth = 4, min_samples_leaf = 25)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "# YOUR CODE HERE\n",
    "dt_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Test your model `dt_model` on the test set `X_test`. Call the ``predict()`` method  to use the fitted model to generate a vector of predictions on the test set. Save the result to the variable ``y_dt_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `dt_rmse` and `dt_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] Root Mean Squared Error: 8.928494906693092e-14\n",
      "[DT] R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Use predict() to test use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_dt_pred = dt_model.predict(X_test) \n",
    "\n",
    "# 2. Compute the RMSE using mean_squared_error()\n",
    "# YOUR CODE HERE\n",
    "dt_rmse = mean_squared_error(y_test, y_dt_pred, squared=False)\n",
    "\n",
    "# 3. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "dt_r2 = r2_score(y_test, y_dt_pred)\n",
    "\n",
    "print('[DT] Root Mean Squared Error: {0}'.format(dt_rmse))\n",
    "print('[DT] R2: {0}'.format(dt_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Fit and Evaluate Two Regression Ensemble Models\n",
    "\n",
    "### a. Fit and Evaluate a Gradient Boosted Decision Tree \n",
    "\n",
    "You will use the scikit-learn `GradientBoostingRegressor` class to create a gradient boosted decision tree. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html).\n",
    "\n",
    "First let's import `GradientBoostingRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you already performed a grid search to find the best model hyperparameters for your gradient boosted decision tree. (We are omitting this step to save computation time.) The best values are: `max_depth=3`, and `n_estimators = 300`. \n",
    "\n",
    "<b>Task</b>: Initialize a `GradientBoostingRegressor` model object with the above values as arguments. Save the result to the variable `gbdt_model`. Fit the `gbdt_model` model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...')\n",
    "\n",
    "# 1. Create the  model object below and assign to variable 'gbdt_model'\n",
    "# YOUR CODE HERE\n",
    "gbdt_model = GradientBoostingRegressor(max_depth=3, n_estimators = 300)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "# YOUR CODE HERE\n",
    "gbdt_model.fit(X_train, y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your model `gbdt_model` on the test set `X_test`. Save the result to the variable ``y_gbdt_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `gbdt_rmse` and `gbdt_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GBDT] Root Mean Squared Error: 0.00030088678003379785\n",
      "[GBDT] R2: 0.9999999095177206\n"
     ]
    }
   ],
   "source": [
    "# 1. Use predict() to test use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_gbdt_pred = gbdt_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE using mean_squared_error() \n",
    "# YOUR CODE HERE\n",
    "gbdt_rmse = mean_squared_error(y_test, y_gbdt_pred, squared=False)\n",
    "\n",
    "# 3. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "gbdt_r2 = r2_score(y_test, y_gbdt_pred)             \n",
    "\n",
    "print('[GBDT] Root Mean Squared Error: {0}'.format(gbdt_rmse))\n",
    "print('[GBDT] R2: {0}'.format(gbdt_r2))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Fit and Evaluate a Random Forest\n",
    "\n",
    "You will use the scikit-learn `RandomForestRegressor` class to create a gradient boosted decision tree. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "First let's import `RandomForestRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you already performed a grid search to find the best model hyperparameters for your random forest model. (We are omitting this step to save computation time.) The best values are: `max_depth=32`, and `n_estimators = 300`. \n",
    "\n",
    "<b>Task</b>: Initialize a `RandomForestRegressor` model object with the above values as arguments. Save the result to the variable `rf_model`. Fit the `rf_model` model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...')\n",
    "\n",
    "# 1. Create the  model object below and assign to variable 'rf_model'\n",
    "# YOUR CODE HERE\n",
    "rf_model = RandomForestRegressor(max_depth=32, n_estimators = 300)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "# YOUR CODE HERE\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your model `rf_model` on the test set `X_test`. Save the result to the variable ``y_rf_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `rf_rmse` and `rf_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] Root Mean Squared Error: 4.870384387148552e-14\n",
      "[RF] R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Use predict() to test use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE using mean_squared_error()\n",
    "# YOUR CODE HERE\n",
    "rf_rmse = mean_squared_error(y_test, y_rf_pred, squared=False)\n",
    "\n",
    "# 3. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "rf_r2 = r2_score(y_test, y_rf_pred) \n",
    "                   \n",
    "print('[RF] Root Mean Squared Error: {0}'.format(rf_rmse))\n",
    "print('[RF] R2: {0}'.format(rf_r2))    \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualize Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below plots the RMSE and R2 score for each regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_Results = [lr_rmse, dt_rmse, gbdt_rmse, rf_rmse]\n",
    "R2_Results = [lr_r2, dt_r2, gbdt_r2, rf_r2]\n",
    "labels = ['LR', 'DT', 'GBDT', 'RF']\n",
    "\n",
    "rg= np.arange(4)\n",
    "width = 0.35\n",
    "plt.bar(rg, RMSE_Results, width, label=\"RMSE\")\n",
    "plt.bar(rg+width, R2_Results, width, label='R2')\n",
    "plt.xticks(rg + width/2, labels)\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE/R2\")\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>:  We invite you to analyze the relative performance of the models you trained. Is there a trend to what settings tend to lead to better performance? Would you say that the best model performs well enough for business purposes? How would you try to improve it? Record your findings in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Double click this Markdown cell to make it editable, and record your findings here.>\n",
    "According the the performance graph above, the values for RMSE are so small that the plot sees them as insignificant values but we know that because the computations are negative this isn't the case. However, each model has an extremely high accuracy which, as discussed in this unit, is not actually a good thing because this means our models have a high risk of overfitting and failure to generalize new data. The trend in higher performing models is using lower values for hyperparamters, but because of the extremely high accuracy I don't think these models would perform well for business purposes (at least the models we created here)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
